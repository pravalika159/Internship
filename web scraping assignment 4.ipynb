{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c246e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import NoSuchElementException,StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f66e7",
   "metadata": {},
   "source": [
    "## 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b6beb",
   "metadata": {},
   "source": [
    "A)Rank \n",
    "B) Name\n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9f5a2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube=webdriver.Chrome()\n",
    "youtube.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "61078cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "table=youtube.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]')\n",
    "for i in table:\n",
    "    try:\n",
    "        names1=youtube.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "        for a in names1:\n",
    "                Name.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "    try:\n",
    "        artists=youtube.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "        for a in names1:\n",
    "            Artist.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist.append('-')\n",
    "    try:\n",
    "        dates=youtube.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "        for a in names1:\n",
    "            Upload_date.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Upload_date.append('-')\n",
    "    try:\n",
    "        views=youtube.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "        for a in names1:\n",
    "            Views.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Views.append('-')\n",
    "print(len(Name))\n",
    "print(len(Artist))\n",
    "print(len(Upload_date))\n",
    "print(len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9def9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIDEO NAMES</th>\n",
       "      <th>ARTISTS</th>\n",
       "      <th>UPLOAD DATE</th>\n",
       "      <th>VIEWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"[20]</td>\n",
       "      <td>\"Shape of You\"[20]</td>\n",
       "      <td>\"Shape of You\"[20]</td>\n",
       "      <td>\"Shape of You\"[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[23]</td>\n",
       "      <td>\"See You Again\"[23]</td>\n",
       "      <td>\"See You Again\"[23]</td>\n",
       "      <td>\"See You Again\"[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[38]</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[38]</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[38]</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"[40]</td>\n",
       "      <td>\"Sugar\"[40]</td>\n",
       "      <td>\"Sugar\"[40]</td>\n",
       "      <td>\"Sugar\"[40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Sorry\"[46]</td>\n",
       "      <td>\"Sorry\"[46]</td>\n",
       "      <td>\"Sorry\"[46]</td>\n",
       "      <td>\"Sorry\"[46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[47]</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[47]</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[47]</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        VIDEO NAMES  \\\n",
       "0                             \"Baby Shark Dance\"[7]   \n",
       "1                                   \"Despacito\"[10]   \n",
       "2                        \"Johny Johny Yes Papa\"[18]   \n",
       "3                                   \"Bath Song\"[19]   \n",
       "4                                \"Shape of You\"[20]   \n",
       "5                               \"See You Again\"[23]   \n",
       "6                           \"Wheels on the Bus\"[28]   \n",
       "7                 \"Phonics Song with Two Words\"[29]   \n",
       "8                                 \"Uptown Funk\"[30]   \n",
       "9                               \"Gangnam Style\"[31]   \n",
       "10  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11                             \"Dame Tu Cosita\"[37]   \n",
       "12   \"Masha and the Bear – Recipe for Disaster\"[38]   \n",
       "13                                     \"Axel F\"[39]   \n",
       "14                                      \"Sugar\"[40]   \n",
       "15                        \"Baa Baa Black Sheep\"[41]   \n",
       "16                             \"Counting Stars\"[42]   \n",
       "17                             \"Lakdi Ki Kathi\"[43]   \n",
       "18                                       \"Roar\"[44]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20                                      \"Sorry\"[46]   \n",
       "21                      \"Shree Hanuman Chalisa\"[47]   \n",
       "22          \"Humpty the train on a fruits ride\"[48]   \n",
       "23                          \"Thinking Out Loud\"[49]   \n",
       "24                                    \"Perfect\"[50]   \n",
       "25                                 \"Dark Horse\"[51]   \n",
       "26                                 \"Let Her Go\"[52]   \n",
       "27                                      \"Faded\"[53]   \n",
       "28                             \"Girls Like You\"[54]   \n",
       "29                                    \"Lean On\"[55]   \n",
       "\n",
       "                                            ARTISTS  \\\n",
       "0                             \"Baby Shark Dance\"[7]   \n",
       "1                                   \"Despacito\"[10]   \n",
       "2                        \"Johny Johny Yes Papa\"[18]   \n",
       "3                                   \"Bath Song\"[19]   \n",
       "4                                \"Shape of You\"[20]   \n",
       "5                               \"See You Again\"[23]   \n",
       "6                           \"Wheels on the Bus\"[28]   \n",
       "7                 \"Phonics Song with Two Words\"[29]   \n",
       "8                                 \"Uptown Funk\"[30]   \n",
       "9                               \"Gangnam Style\"[31]   \n",
       "10  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11                             \"Dame Tu Cosita\"[37]   \n",
       "12   \"Masha and the Bear – Recipe for Disaster\"[38]   \n",
       "13                                     \"Axel F\"[39]   \n",
       "14                                      \"Sugar\"[40]   \n",
       "15                        \"Baa Baa Black Sheep\"[41]   \n",
       "16                             \"Counting Stars\"[42]   \n",
       "17                             \"Lakdi Ki Kathi\"[43]   \n",
       "18                                       \"Roar\"[44]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20                                      \"Sorry\"[46]   \n",
       "21                      \"Shree Hanuman Chalisa\"[47]   \n",
       "22          \"Humpty the train on a fruits ride\"[48]   \n",
       "23                          \"Thinking Out Loud\"[49]   \n",
       "24                                    \"Perfect\"[50]   \n",
       "25                                 \"Dark Horse\"[51]   \n",
       "26                                 \"Let Her Go\"[52]   \n",
       "27                                      \"Faded\"[53]   \n",
       "28                             \"Girls Like You\"[54]   \n",
       "29                                    \"Lean On\"[55]   \n",
       "\n",
       "                                        UPLOAD DATE  \\\n",
       "0                             \"Baby Shark Dance\"[7]   \n",
       "1                                   \"Despacito\"[10]   \n",
       "2                        \"Johny Johny Yes Papa\"[18]   \n",
       "3                                   \"Bath Song\"[19]   \n",
       "4                                \"Shape of You\"[20]   \n",
       "5                               \"See You Again\"[23]   \n",
       "6                           \"Wheels on the Bus\"[28]   \n",
       "7                 \"Phonics Song with Two Words\"[29]   \n",
       "8                                 \"Uptown Funk\"[30]   \n",
       "9                               \"Gangnam Style\"[31]   \n",
       "10  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11                             \"Dame Tu Cosita\"[37]   \n",
       "12   \"Masha and the Bear – Recipe for Disaster\"[38]   \n",
       "13                                     \"Axel F\"[39]   \n",
       "14                                      \"Sugar\"[40]   \n",
       "15                        \"Baa Baa Black Sheep\"[41]   \n",
       "16                             \"Counting Stars\"[42]   \n",
       "17                             \"Lakdi Ki Kathi\"[43]   \n",
       "18                                       \"Roar\"[44]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20                                      \"Sorry\"[46]   \n",
       "21                      \"Shree Hanuman Chalisa\"[47]   \n",
       "22          \"Humpty the train on a fruits ride\"[48]   \n",
       "23                          \"Thinking Out Loud\"[49]   \n",
       "24                                    \"Perfect\"[50]   \n",
       "25                                 \"Dark Horse\"[51]   \n",
       "26                                 \"Let Her Go\"[52]   \n",
       "27                                      \"Faded\"[53]   \n",
       "28                             \"Girls Like You\"[54]   \n",
       "29                                    \"Lean On\"[55]   \n",
       "\n",
       "                                              VIEWS  \n",
       "0                             \"Baby Shark Dance\"[7]  \n",
       "1                                   \"Despacito\"[10]  \n",
       "2                        \"Johny Johny Yes Papa\"[18]  \n",
       "3                                   \"Bath Song\"[19]  \n",
       "4                                \"Shape of You\"[20]  \n",
       "5                               \"See You Again\"[23]  \n",
       "6                           \"Wheels on the Bus\"[28]  \n",
       "7                 \"Phonics Song with Two Words\"[29]  \n",
       "8                                 \"Uptown Funk\"[30]  \n",
       "9                               \"Gangnam Style\"[31]  \n",
       "10  \"Learning Colors – Colorful Eggs on a Farm\"[36]  \n",
       "11                             \"Dame Tu Cosita\"[37]  \n",
       "12   \"Masha and the Bear – Recipe for Disaster\"[38]  \n",
       "13                                     \"Axel F\"[39]  \n",
       "14                                      \"Sugar\"[40]  \n",
       "15                        \"Baa Baa Black Sheep\"[41]  \n",
       "16                             \"Counting Stars\"[42]  \n",
       "17                             \"Lakdi Ki Kathi\"[43]  \n",
       "18                                       \"Roar\"[44]  \n",
       "19           \"Waka Waka (This Time for Africa)\"[45]  \n",
       "20                                      \"Sorry\"[46]  \n",
       "21                      \"Shree Hanuman Chalisa\"[47]  \n",
       "22          \"Humpty the train on a fruits ride\"[48]  \n",
       "23                          \"Thinking Out Loud\"[49]  \n",
       "24                                    \"Perfect\"[50]  \n",
       "25                                 \"Dark Horse\"[51]  \n",
       "26                                 \"Let Her Go\"[52]  \n",
       "27                                      \"Faded\"[53]  \n",
       "28                             \"Girls Like You\"[54]  \n",
       "29                                    \"Lean On\"[55]  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'VIDEO NAMES':Name,'ARTISTS':Artist,'UPLOAD DATE':Upload_date,\n",
    "                 'VIEWS':Views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4c60f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0144e8",
   "metadata": {},
   "source": [
    "## 2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/ .You need to find following details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db3120",
   "metadata": {},
   "source": [
    "A) Series \n",
    "B) Place \n",
    "C) Date \n",
    "D) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9473eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a7e0a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "fixture.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "09fdb918",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series=[]\n",
    "place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "table=driver.find_elements(By.XPATH,'//div[@class=\"tab-inner-content\"]')\n",
    "for i in table:\n",
    "    try:\n",
    "        ser=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "        for a in ser:\n",
    "            Series.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append('-')\n",
    "    try:\n",
    "        plac=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "        for a in plac:\n",
    "            place.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        place.append('-')\n",
    "    try:\n",
    "        date=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "        for a in date:\n",
    "            Date.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('-')\n",
    "    try:\n",
    "        time=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "        for a in time:\n",
    "            Time.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Time.append('-')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e77029b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIES</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>6 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>9 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>5 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>9 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>12 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           SERIES  \\\n",
       "0  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "1  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "2                     ICC MENS T20 WORLD CUP 2024   \n",
       "3                     ICC MENS T20 WORLD CUP 2024   \n",
       "4                     ICC MENS T20 WORLD CUP 2024   \n",
       "5                     ICC MENS T20 WORLD CUP 2024   \n",
       "6                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "7                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "8                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               PLACE           DATE  \\\n",
       "0       Sylhet International Cricket Stadium, Sylhet    6 MAY, 2024   \n",
       "1       Sylhet International Cricket Stadium, Sylhet    9 MAY, 2024   \n",
       "2  Nassau County International Cricket Stadium, N...   5 JUNE, 2024   \n",
       "3  Nassau County International Cricket Stadium, N...   9 JUNE, 2024   \n",
       "4  Nassau County International Cricket Stadium, N...  12 JUNE, 2024   \n",
       "5  Central Broward Park & Broward County Stadium,...  15 JUNE, 2024   \n",
       "6                         Harare Sports Club, Harare   6 JULY, 2024   \n",
       "7                         Harare Sports Club, Harare   7 JULY, 2024   \n",
       "8                         Harare Sports Club, Harare  10 JULY, 2024   \n",
       "\n",
       "          TIME  \n",
       "0  3:30 PM IST  \n",
       "1  3:30 PM IST  \n",
       "2  8:00 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  \n",
       "6  8:00 PM IST  \n",
       "7  8:00 PM IST  \n",
       "8  8:00 PM IST  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'SERIES':Series,'PLACE':place,'DATE':Date,'TIME':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "41568175",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73ca184",
   "metadata": {},
   "source": [
    "## 3. Scrape the details of State-wise GDP of India from statisticstime.com.Url = http://statisticstimes.com/ You have to find following details: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8db20c",
   "metadata": {},
   "source": [
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a463110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9d4ba479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6e7928ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Raised: Message: element not interactable\n",
      "  (Session info: chrome=124.0.6367.119)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6A8B51502+60802]\n",
      "\t(No symbol) [0x00007FF6A8ACAC02]\n",
      "\t(No symbol) [0x00007FF6A8987B13]\n",
      "\t(No symbol) [0x00007FF6A89D8052]\n",
      "\t(No symbol) [0x00007FF6A89CAE8B]\n",
      "\t(No symbol) [0x00007FF6A89FAB7A]\n",
      "\t(No symbol) [0x00007FF6A89CA7C6]\n",
      "\t(No symbol) [0x00007FF6A89FAD90]\n",
      "\t(No symbol) [0x00007FF6A8A1A224]\n",
      "\t(No symbol) [0x00007FF6A89FA923]\n",
      "\t(No symbol) [0x00007FF6A89C8FEC]\n",
      "\t(No symbol) [0x00007FF6A89C9C21]\n",
      "\tGetHandleVerifier [0x00007FF6A8E5411D+3217821]\n",
      "\tGetHandleVerifier [0x00007FF6A8E960B7+3488055]\n",
      "\tGetHandleVerifier [0x00007FF6A8E8F03F+3459263]\n",
      "\tGetHandleVerifier [0x00007FF6A8C0B846+823494]\n",
      "\t(No symbol) [0x00007FF6A8AD5F9F]\n",
      "\t(No symbol) [0x00007FF6A8AD0EC4]\n",
      "\t(No symbol) [0x00007FF6A8AD1052]\n",
      "\t(No symbol) [0x00007FF6A8AC18A4]\n",
      "\tBaseThreadInitThunk [0x00007FFE2C7E257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFE2E24AA48+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    economy=driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/button')\n",
    "    a=driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/div/a[3]')\n",
    "    a.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print('Exception Raised:',e)\n",
    "    b=driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/div/a[3]')\n",
    "    driver.get(a.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "034c028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_indian_states=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "GDP_indian_states.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "84f144f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State=[]\n",
    "GSDP21_22=[]\n",
    "GSDP22_23=[]\n",
    "Share21_22=[]\n",
    "GDP=[]\n",
    "GSDP_table=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]')\n",
    "for i in GSDP_table:\n",
    "    try:\n",
    "        rank=driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody[1]/tr/td[1]')\n",
    "        for a in rank:\n",
    "            Rank.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Rank.append('-')\n",
    "    try:\n",
    "        state=driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody[1]/tr/td[2]')\n",
    "        for a in state:\n",
    "            State.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        State.append('-')\n",
    "    try:\n",
    "        gsdp21_22=driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody[1]/tr/td[5]')\n",
    "        for a in gsdp21_22:\n",
    "            GSDP21_22.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP21_22.append('-')\n",
    "    try:\n",
    "        gsdp22_23=driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody[1]/tr/td[4]')\n",
    "        for a in gsdp22_23:\n",
    "            GSDP22_23.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP22_23.append('-')\n",
    "    try:\n",
    "        share21_22=driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody[1]/tr/td[6]')\n",
    "        for a in share21_22:\n",
    "            Share21_22.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        Share21_22.append('-')\n",
    "    try:\n",
    "        gdp=driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody[1]/tr/td[7]')\n",
    "        for a in gdp:\n",
    "            GDP.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        GDP.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e03fad07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP(21-22)</th>\n",
       "      <th>GSDP(22-23)</th>\n",
       "      <th>SHARE(21-22)</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>-</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>934,542</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>881,336</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>868,905</td>\n",
       "      <td>984,055</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>662,886</td>\n",
       "      <td>753,177</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>650,302</td>\n",
       "      <td>751,396</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>617,192</td>\n",
       "      <td>676,164</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>411,454</td>\n",
       "      <td>493,167</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>410,525</td>\n",
       "      <td>464,399</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>358,863</td>\n",
       "      <td>393,722</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>267,143</td>\n",
       "      <td>303,781</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>193,352</td>\n",
       "      <td>224,226</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>172,162</td>\n",
       "      <td>191,728</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>84,266</td>\n",
       "      <td>93,672</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>62,550</td>\n",
       "      <td>72,636</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>46,096</td>\n",
       "      <td>54,285</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>43,810</td>\n",
       "      <td>49,643</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>38,785</td>\n",
       "      <td>42,697</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>37,557</td>\n",
       "      <td>42,756</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>36,594</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>34,775</td>\n",
       "      <td>39,630</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>31,038</td>\n",
       "      <td>35,643</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>27,824</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>10,371</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE GSDP(21-22) GSDP(22-23) SHARE(21-22)  \\\n",
       "0     1                Maharashtra   3,108,022           -       13.17%   \n",
       "1     2                 Tamil Nadu   2,071,286   2,364,514        8.78%   \n",
       "2     3                  Karnataka   1,978,094   2,269,995        8.38%   \n",
       "3     4              Uttar Pradesh   1,975,595   2,258,040        8.37%   \n",
       "4     5                    Gujarat   1,928,683   2,230,609        8.17%   \n",
       "5     6                West Bengal   1,329,238   1,531,758        5.63%   \n",
       "6     7                  Rajasthan   1,193,489   1,365,849        5.06%   \n",
       "7     8             Andhra Pradesh   1,148,471   1,303,524        4.87%   \n",
       "8     9                  Telangana   1,124,204   1,308,034        4.76%   \n",
       "9    10             Madhya Pradesh   1,092,964   1,246,471        4.63%   \n",
       "10   11                     Kerala     934,542   1,046,188        3.96%   \n",
       "11   12                      Delhi     881,336   1,014,688        3.73%   \n",
       "12   13                    Haryana     868,905     984,055        3.68%   \n",
       "13   14                     Odisha     662,886     753,177        2.81%   \n",
       "14   15                      Bihar     650,302     751,396        2.76%   \n",
       "15   16                     Punjab     617,192     676,164        2.62%   \n",
       "16   17                      Assam     411,454     493,167        1.74%   \n",
       "17   18               Chhattisgarh     410,525     464,399        1.74%   \n",
       "18   19                  Jharkhand     358,863     393,722        1.52%   \n",
       "19   20                Uttarakhand     267,143     303,781        1.13%   \n",
       "20   21            Jammu & Kashmir     193,352     224,226        0.82%   \n",
       "21   22           Himachal Pradesh     172,162     191,728        0.73%   \n",
       "22   23                        Goa      84,266      93,672        0.36%   \n",
       "23   24                    Tripura      62,550      72,636        0.27%   \n",
       "24   25                 Chandigarh      46,096      54,285        0.20%   \n",
       "25   26                 Puducherry      43,810      49,643        0.19%   \n",
       "26   27                  Meghalaya      38,785      42,697        0.16%   \n",
       "27   28                     Sikkim      37,557      42,756        0.16%   \n",
       "28   29                    Manipur      36,594           -        0.16%   \n",
       "29   30          Arunachal Pradesh      34,775      39,630        0.15%   \n",
       "30   31                   Nagaland      31,038      35,643        0.13%   \n",
       "31   32                    Mizoram      27,824           -        0.12%   \n",
       "32   33  Andaman & Nicobar Islands      10,371           -        0.04%   \n",
       "\n",
       "        GDP  \n",
       "0   414.928  \n",
       "1   276.522  \n",
       "2   264.080  \n",
       "3   263.747  \n",
       "4   257.484  \n",
       "5   177.456  \n",
       "6   159.334  \n",
       "7   153.324  \n",
       "8   150.084  \n",
       "9   145.913  \n",
       "10  124.764  \n",
       "11  117.660  \n",
       "12  116.001  \n",
       "13   88.497  \n",
       "14   86.817  \n",
       "15   82.397  \n",
       "16   54.930  \n",
       "17   54.806  \n",
       "18   47.909  \n",
       "19   35.664  \n",
       "20   25.813  \n",
       "21   22.984  \n",
       "22   11.250  \n",
       "23    8.351  \n",
       "24    6.154  \n",
       "25    5.849  \n",
       "26    5.178  \n",
       "27    5.014  \n",
       "28    4.885  \n",
       "29    4.643  \n",
       "30    4.144  \n",
       "31    3.715  \n",
       "32    1.385  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'RANK':Rank[:33],'STATE':State[:33],'GSDP(21-22)':GSDP21_22[:33],'GSDP(22-23)':GSDP22_23[:33],\n",
    "                 'SHARE(21-22)':Share21_22[:33],'GDP':GDP[:33]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aafd5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba2429e",
   "metadata": {},
   "source": [
    "## 4. Scrape the details of trending repositories on Github.com. Url = https://github.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bda828",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65f77246",
   "metadata": {},
   "outputs": [],
   "source": [
    "github=webdriver.Chrome()\n",
    "github.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfd0ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore=github.find_element(By.CLASS_NAME,'Button-label')\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec270311",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_source=github.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "open_source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "711534af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending=github.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b779f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Description=[]\n",
    "contributors_count=[]\n",
    "Language=[]\n",
    "try:\n",
    "    title=github.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "    for i in title:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Title.append('-') \n",
    "try:\n",
    "    descript=github.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "    for i in descript:\n",
    "        Description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Description.append('-')\n",
    "try:\n",
    "    lang=github.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]/span[2]')\n",
    "    for i in lang:\n",
    "        Language.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Language.append('-') \n",
    "try:\n",
    "    count=github.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"][2]')\n",
    "    for c in count:\n",
    "        contributors_count.append(c.text)\n",
    "except NoSuchElementException:\n",
    "    contributors_count.append('-') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a2a8cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "24\n",
      "23\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(Title))\n",
    "print(len(Description))\n",
    "print(len(Language))\n",
    "print(len(contributors_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "810284e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "github.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f180e90",
   "metadata": {},
   "source": [
    "## 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb55041",
   "metadata": {},
   "source": [
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b63ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7b3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button')\n",
    "menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2203686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button')\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a26e4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_100_pages=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "hot_100_pages.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "012e46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name=[]\n",
    "artist_name=[]\n",
    "last_week_rank=[]\n",
    "peak_rank=[]\n",
    "weeks_on_board=[]\n",
    "try:\n",
    "    song=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "    for s in song:\n",
    "        song_name.append(s.text)\n",
    "except NoSuchElementException:\n",
    "    song_name.append('-') \n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul[1]/li[1]/span[1]')\n",
    "    for a in artist:\n",
    "        artist_name.append(a.text)\n",
    "except NoSuchElementException:\n",
    "    artist_name.append('-') \n",
    "try:\n",
    "    last=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-row u-background-color-grey-lightest@mobile-max\"]/li[3]/span')\n",
    "    for l in last:\n",
    "        last_week_rank.append(l.text)\n",
    "except NoSuchElementException:\n",
    "    last_week_rank.append('-') \n",
    "try:\n",
    "    peak=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-row u-background-color-grey-lightest@mobile-max\"]/li[4]/span')\n",
    "    for p in peak:\n",
    "        peak_rank.append(p.text)\n",
    "except NoSuchElementException:\n",
    "    peak_rank.append('-') \n",
    "try:\n",
    "    board=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-row u-background-color-grey-lightest@mobile-max\"]/li[5]/span')\n",
    "    for b in board:\n",
    "        weeks_on_board.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    weeks_on_board.append('-') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "560833da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SONG NAMES</th>\n",
       "      <th>ARTIST NAMES</th>\n",
       "      <th>LAST WEEK RANK</th>\n",
       "      <th>PEAK RANK</th>\n",
       "      <th>WEEKS ON BOARD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fortnight</td>\n",
       "      <td>Taylor Swift Featuring Post Malone</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Down Bad</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Can Do It With A Broken Heart</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Tortured Poets Department</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So Long, London</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Us Vs. Them</td>\n",
       "      <td>$uicideBoy$</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wine Into Whiskey</td>\n",
       "      <td>Tucker Wetmore</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Spin You Around (1/24)</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>89</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Soak City</td>\n",
       "      <td>310babii</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Selfish</td>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         SONG NAMES                        ARTIST NAMES  \\\n",
       "0                         Fortnight  Taylor Swift Featuring Post Malone   \n",
       "1                          Down Bad                        Taylor Swift   \n",
       "2   I Can Do It With A Broken Heart                        Taylor Swift   \n",
       "3     The Tortured Poets Department                        Taylor Swift   \n",
       "4                   So Long, London                        Taylor Swift   \n",
       "..                              ...                                 ...   \n",
       "95                      Us Vs. Them                         $uicideBoy$   \n",
       "96                Wine Into Whiskey                      Tucker Wetmore   \n",
       "97           Spin You Around (1/24)                       Morgan Wallen   \n",
       "98                        Soak City                            310babii   \n",
       "99                          Selfish                   Justin Timberlake   \n",
       "\n",
       "   LAST WEEK RANK PEAK RANK WEEKS ON BOARD  \n",
       "0               -         1              1  \n",
       "1               -         2              1  \n",
       "2               -         3              1  \n",
       "3               -         4              1  \n",
       "4               -         5              1  \n",
       "..            ...       ...            ...  \n",
       "95              -        96              1  \n",
       "96             84        77              5  \n",
       "97             89        24             13  \n",
       "98             82        53             19  \n",
       "99             60        19             13  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'SONG NAMES':song_name,'ARTIST NAMES':artist_name,'LAST WEEK RANK':last_week_rank,'PEAK RANK':peak_rank,\n",
    "                 'WEEKS ON BOARD':weeks_on_board})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ded9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63280a81",
   "metadata": {},
   "source": [
    "## 6. Scrape the details of Highest selling novels. Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26027e",
   "metadata": {},
   "source": [
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afa3f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "novels=webdriver.Chrome()\n",
    "novels.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4643f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name=[]\n",
    "author_name=[]\n",
    "volumes_sold=[]\n",
    "publishers=[]\n",
    "genre=[]\n",
    "try:\n",
    "    book=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for b in book:\n",
    "        book_name.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    book_name.append('-') \n",
    "try:\n",
    "    author=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for a in author:\n",
    "        author_name.append(a.text)\n",
    "except NoSuchElementException:\n",
    "    author_name.append('-') \n",
    "try:\n",
    "    sold=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for s in sold:\n",
    "        volumes_sold.append(s.text)\n",
    "except NoSuchElementException:\n",
    "    volumes_sold.append('-') \n",
    "try:\n",
    "    publish=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for p in publish:\n",
    "        publishers.append(p.text)\n",
    "except NoSuchElementException:\n",
    "    publishers.append('-')\n",
    "try:\n",
    "    gen=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for g in gen:\n",
    "        genre.append(g.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('-') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e22b1c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOOK NAMES</th>\n",
       "      <th>AUTHOR NAMES</th>\n",
       "      <th>VOLUMES SOLD</th>\n",
       "      <th>publishers</th>\n",
       "      <th>GENRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           BOOK NAMES      AUTHOR NAMES  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   VOLUMES SOLD       publishers                        GENRE  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'BOOK NAMES':book_name,'AUTHOR NAMES':author_name,'VOLUMES SOLD':volumes_sold,'publishers':publishers,\n",
    "                'GENRE':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c723464",
   "metadata": {},
   "outputs": [],
   "source": [
    "novels.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605530d",
   "metadata": {},
   "source": [
    "## 7. Scrape the details most watched tv series of all time from imdb.com. Url = ttps://www.imdb.com/list/ls512407256/ You have to find the following details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785065b",
   "metadata": {},
   "source": [
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Episodes\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2028e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_series=webdriver.Chrome()\n",
    "tv_series.get('https://www.imdb.com/list/ls512407256/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23a66923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=[]\n",
    "span_year=[]\n",
    "genre=[]\n",
    "Episodes=[]\n",
    "ratings=[]\n",
    "votes=[]\n",
    "try:\n",
    "    name=tv_series.find_elements(By.XPATH,'//div[@class=\"sc-74bf520e-3 klvfeN dli-parent\"]/div/div[2]/div[1]')\n",
    "    for n in name:\n",
    "        Names.append(n.text)\n",
    "except NoSuchElementException:\n",
    "    Names.append('-')\n",
    "try:\n",
    "    year=tv_series.find_elements(By.XPATH,'//div[@class=\"sc-74bf520e-3 klvfeN dli-parent\"]/div/div[2]/div[2]/span[1]')\n",
    "    for y in year:\n",
    "        span_year.append(y.text)\n",
    "except NoSuchElementException:\n",
    "    span_year.append('-')\n",
    "try:\n",
    "    gen=tv_series.find_elements(By.XPATH,'//div[@class=\"sc-74bf520e-1 ictulU\"]/div')\n",
    "    for g in gen:\n",
    "        genre.append(g.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('-')\n",
    "try:\n",
    "    episodes=tv_series.find_elements(By.XPATH,'//div[@class=\"sc-74bf520e-3 klvfeN dli-parent\"]/div/div[2]/div[2]/span[2]')\n",
    "    for i in episodes:\n",
    "        Episodes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Episodes.append('-')\n",
    "try:\n",
    "    rati=tv_series.find_elements(By.XPATH,'//span[@class=\"sc-b189961a-1 kcfvgk\"]/div/span[1]')\n",
    "    for i in rati:\n",
    "        ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    ratings.append('-')\n",
    "try:\n",
    "    vote=tv_series.find_elements(By.XPATH,'//span[@class=\"sc-b189961a-1 kcfvgk\"]/div/span[1]/span')\n",
    "    for v in vote:\n",
    "        votes.append(v.text)\n",
    "except NoSuchElementException:\n",
    "    votes.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff24075b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIES NAMES</th>\n",
       "      <th>YEAR OF SPAN</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>EPISODES</th>\n",
       "      <th>RATINGS</th>\n",
       "      <th>VOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Nine noble families fight for control over the...</td>\n",
       "      <td>74 eps</td>\n",
       "      <td>9.2\\n (2.3M)</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things</td>\n",
       "      <td>2016–2025</td>\n",
       "      <td>When a young boy vanishes, a small town uncove...</td>\n",
       "      <td>42 eps</td>\n",
       "      <td>8.7\\n (1.3M)</td>\n",
       "      <td>(1.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Sheriff Deputy Rick Grimes wakes up from a com...</td>\n",
       "      <td>177 eps</td>\n",
       "      <td>8.1\\n (1.1M)</td>\n",
       "      <td>(1.1M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Follows teenager Clay Jensen, in his quest to ...</td>\n",
       "      <td>49 eps</td>\n",
       "      <td>7.5\\n (316K)</td>\n",
       "      <td>(316K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Set 97 years after a nuclear war destroyed civ...</td>\n",
       "      <td>100 eps</td>\n",
       "      <td>7.6\\n (277K)</td>\n",
       "      <td>(277K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196. Reign</td>\n",
       "      <td>2013–2017</td>\n",
       "      <td>Mary, Queen of Scots, faces political and sexu...</td>\n",
       "      <td>78 eps</td>\n",
       "      <td>7.5\\n (54K)</td>\n",
       "      <td>(54K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197. A Series of Unfortunate Events</td>\n",
       "      <td>2017–2019</td>\n",
       "      <td>After the loss of their parents in a mysteriou...</td>\n",
       "      <td>25 eps</td>\n",
       "      <td>7.7\\n (67K)</td>\n",
       "      <td>(67K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198. Criminal Minds</td>\n",
       "      <td>2005–</td>\n",
       "      <td>A group of criminal profilers who work for the...</td>\n",
       "      <td>344 eps</td>\n",
       "      <td>8.1\\n (219K)</td>\n",
       "      <td>(219K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199. Scream: The TV Series</td>\n",
       "      <td>2015–2019</td>\n",
       "      <td>A serialized anthology series that follows a g...</td>\n",
       "      <td>29 eps</td>\n",
       "      <td>7.0\\n (45K)</td>\n",
       "      <td>(45K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200. The Haunting of Hill House</td>\n",
       "      <td>2018</td>\n",
       "      <td>Flashing between past and present, a fractured...</td>\n",
       "      <td>10 eps</td>\n",
       "      <td>8.5\\n (289K)</td>\n",
       "      <td>(289K)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SERIES NAMES YEAR OF SPAN  \\\n",
       "0                     1. Game of Thrones    2011–2019   \n",
       "1                     2. Stranger Things    2016–2025   \n",
       "2                    3. The Walking Dead    2010–2022   \n",
       "3                      4. 13 Reasons Why    2017–2020   \n",
       "4                             5. The 100    2014–2020   \n",
       "..                                   ...          ...   \n",
       "195                           196. Reign    2013–2017   \n",
       "196  197. A Series of Unfortunate Events    2017–2019   \n",
       "197                  198. Criminal Minds        2005–   \n",
       "198           199. Scream: The TV Series    2015–2019   \n",
       "199      200. The Haunting of Hill House         2018   \n",
       "\n",
       "                                                 GENRE EPISODES       RATINGS  \\\n",
       "0    Nine noble families fight for control over the...   74 eps  9.2\\n (2.3M)   \n",
       "1    When a young boy vanishes, a small town uncove...   42 eps  8.7\\n (1.3M)   \n",
       "2    Sheriff Deputy Rick Grimes wakes up from a com...  177 eps  8.1\\n (1.1M)   \n",
       "3    Follows teenager Clay Jensen, in his quest to ...   49 eps  7.5\\n (316K)   \n",
       "4    Set 97 years after a nuclear war destroyed civ...  100 eps  7.6\\n (277K)   \n",
       "..                                                 ...      ...           ...   \n",
       "195  Mary, Queen of Scots, faces political and sexu...   78 eps   7.5\\n (54K)   \n",
       "196  After the loss of their parents in a mysteriou...   25 eps   7.7\\n (67K)   \n",
       "197  A group of criminal profilers who work for the...  344 eps  8.1\\n (219K)   \n",
       "198  A serialized anthology series that follows a g...   29 eps   7.0\\n (45K)   \n",
       "199  Flashing between past and present, a fractured...   10 eps  8.5\\n (289K)   \n",
       "\n",
       "       VOTES  \n",
       "0     (2.3M)  \n",
       "1     (1.3M)  \n",
       "2     (1.1M)  \n",
       "3     (316K)  \n",
       "4     (277K)  \n",
       "..       ...  \n",
       "195    (54K)  \n",
       "196    (67K)  \n",
       "197   (219K)  \n",
       "198    (45K)  \n",
       "199   (289K)  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'SERIES NAMES':Names,'YEAR OF SPAN':span_year,'GENRE':genre,'EPISODES':Episodes,'RATINGS':ratings,\n",
    "                 'VOTES':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a18c3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_series.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c2b27",
   "metadata": {},
   "source": [
    "## 8. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/ You have to find the following details:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e13f6",
   "metadata": {},
   "source": [
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute \n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7558af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_repositories=webdriver.Chrome()\n",
    "ml_repositories.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bf9609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_datasets=ml_repositories.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "view_datasets.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b0cfccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_all=ml_repositories.find_element(By.XPATH,'//div[@class=\"swap\"][2]')\n",
    "expand_all.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f631a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name=[]\n",
    "data_type=[]\n",
    "Task=[]\n",
    "attribute_type=[]\n",
    "no_of_instances=[]\n",
    "no_of_attributes=[]\n",
    "Year=[]\n",
    "try:\n",
    "    dataset_name=ml_repositories.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]/a')\n",
    "    for n in dataset_name:\n",
    "        Dataset_name.append(n.text)\n",
    "except NoSuchElementException:\n",
    "    Dataset_name.append('-')\n",
    "try:\n",
    "    datatype=ml_repositories.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[2]')\n",
    "    for t in datatype:\n",
    "        data_type.append(t.text)\n",
    "except NoSuchElementException:\n",
    "    data_type.append('-')\n",
    "try:\n",
    "    task=ml_repositories.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span')\n",
    "    for s in task:\n",
    "        Task.append(s.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('-')\n",
    "try:\n",
    "    attr_type=ml_repositories.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "    for t in attr_type:\n",
    "        attribute_type.append(t.text)\n",
    "except NoSuchElementException:\n",
    "    attribute_type.append('-')\n",
    "try:\n",
    "    instances=ml_repositories.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span')\n",
    "    for i in instances:\n",
    "        no_of_instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_instances.append('-')\n",
    "try:\n",
    "    attributes=ml_repositories.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "    for n in attributes:\n",
    "        no_of_attributes.append(n.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_attributes.append('-')\n",
    "try:\n",
    "    year=ml_repositories.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[3]')\n",
    "    for y in year:\n",
    "        Year.append(y.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4946d8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATASET NAMES</th>\n",
       "      <th>DATA TYPES</th>\n",
       "      <th>TASK</th>\n",
       "      <th>ATTRIBUTE TYPE</th>\n",
       "      <th>NUMBER OF INSTANCES</th>\n",
       "      <th>NUMBER OF ATTRIBUTES</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>8/14/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Real</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          DATASET NAMES                  DATA TYPES  \\\n",
       "0                                  Iris                        Real   \n",
       "1                         Heart Disease  Categorical, Integer, Real   \n",
       "2                              Dry Bean               Integer, Real   \n",
       "3            Rice (Cammeo and Osmancik)                        Real   \n",
       "4                                 Adult        Categorical, Integer   \n",
       "5  Breast Cancer Wisconsin (Diagnostic)                        Real   \n",
       "6                                Raisin               Real, Integer   \n",
       "7                                  Wine               Integer, Real   \n",
       "8                          Wine Quality                        Real   \n",
       "9                              Diabetes        Categorical, Integer   \n",
       "\n",
       "                         TASK             ATTRIBUTE TYPE NUMBER OF INSTANCES  \\\n",
       "0              Classification                    Tabular       150 Instances   \n",
       "1              Classification               Multivariate       303 Instances   \n",
       "2              Classification               Multivariate    13.61K Instances   \n",
       "3              Classification               Multivariate     3.81K Instances   \n",
       "4              Classification               Multivariate    48.84K Instances   \n",
       "5              Classification               Multivariate       569 Instances   \n",
       "6              Classification               Multivariate       900 Instances   \n",
       "7              Classification                    Tabular       178 Instances   \n",
       "8  Classification, Regression               Multivariate      4.9K Instances   \n",
       "9              Classification  Multivariate, Time-Series         1 Instances   \n",
       "\n",
       "  NUMBER OF ATTRIBUTES       YEAR  \n",
       "0           4 Features   7/1/1988  \n",
       "1          13 Features   7/1/1988  \n",
       "2          16 Features  9/14/2020  \n",
       "3           7 Features  10/6/2019  \n",
       "4          14 Features   5/1/1996  \n",
       "5          30 Features  11/1/1995  \n",
       "6           8 Features  8/14/2023  \n",
       "7          13 Features   7/1/1991  \n",
       "8          12 Features  10/7/2009  \n",
       "9          20 Features        N/A  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'DATASET NAMES':Dataset_name,'DATA TYPES':data_type,'TASK':Task,'ATTRIBUTE TYPE':attribute_type,\n",
    "'NUMBER OF INSTANCES':no_of_instances,'NUMBER OF ATTRIBUTES':no_of_attributes,'YEAR':Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40215de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_repositories.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b2d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
