{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01635761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670f0bf",
   "metadata": {},
   "source": [
    "### 1) Write a python program to display IMDB’s Top rated 100 Indian movies’ data https://www.imdb.com/list/ls056092300/ (i.e. name, rating, year ofrelease) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8384b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.imdb.com/list/ls056092300/\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7926d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f7a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ship of Theseus', 'Iruvar', 'Kaagaz Ke Phool', 'Lagaan: Once Upon a Time in India', 'Pather Panchali', 'Charulata', 'Rang De Basanti', 'Dev.D', '3 Idiots', 'Awaara', 'Nayakan', 'Aparajito', 'Pushpaka Vimana', 'Pyaasa', 'Ghatashraddha', 'Sholay', 'Aradhana', 'Do Ankhen Barah Haath', 'Bombay', 'Neecha Nagar', 'Do Bigha Zamin', 'Garm Hava', 'Piravi', 'Mughal-E-Azam', 'Amma Ariyan', 'Madhumati', 'Goopy Gyne Bagha Byne', 'Gangs of Wasseypur', 'Guide', 'Satya', 'Roja', 'Mr. India', 'The Cloud-Capped Star', 'Harishchandrachi Factory', 'Masoom', 'Agneepath', 'Tabarana Kathe', 'Zakhm', 'Dil Chahta Hai', 'Bhaag Milkha Bhaag', 'Chupke Chupke', 'Dilwale Dulhania Le Jayenge', 'Taare Zameen Par', 'Ardh Satya', 'Bhumika', 'Enthiran', 'Sadma', 'Shwaas', 'Lamhe', 'Haqeeqat', 'Shree 420', 'Kannathil Muthamittal', 'Hum Aapke Hain Koun..!', 'Ustad Hotel', 'Bandit Queen', 'Lakshya', 'Black Friday', 'Manthan', 'Apoorva Raagangal', 'English Vinglish', 'Jewel Thief', 'Pakeezah', 'Maqbool', 'Jis Desh Men Ganga Behti Hai', 'Sahib Bibi Aur Ghulam', 'Shatranj Ke Khilari', 'Narthanasala', 'Chandni Bar', 'Vaaranam Aayiram', 'Mr. and Mrs. Iyer', 'Chandni', 'English, August', 'Celluloid', 'Sagara Sangamam', 'Munna Bhai M.B.B.S.', 'Saaransh', 'Guddi', 'Vanaja', 'Vazhakku Enn 18/9', 'Gangaajal', 'Angoor', 'Guru', 'Andaz Apna Apna', 'Sangam', 'Oka Oori Katha', 'Bhuvan Shome', 'Border', 'Parineeta', 'Devdas', 'Abohomaan', 'Kuch Kuch Hota Hai', 'Pithamagan', 'Veyyil', 'Chemmeen', 'Jaane Bhi Do Yaaro', 'Apur Sansar', 'Kanchivaram', 'Monsoon Wedding', 'Black', 'Deewaar']\n"
     ]
    }
   ],
   "source": [
    "names=[]\n",
    "for i in data.find_all('h3',class_=\"lister-item-header\"):\n",
    "    name=i.a.text\n",
    "    names.append(name.strip())\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614fd620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8', '8.4', '7.8', '8.1', '8.2', '8.1', '8.1', '7.9', '8.4', '7.8', '8.6', '8.2', '8.6', '8.3', '7.6', '8.1', '7.6', '8.4', '8.1', '6.6', '8.3', '8', '7.8', '8.1', '7.4', '7.8', '8.7', '8.2', '8.3', '8.3', '8.1', '7.7', '7.8', '8.4', '8.4', '7.6', '8.1', '7.9', '8.1', '8.2', '8.3', '8', '8.3', '8.1', '7.4', '7.1', '8.3', '8.2', '7.2', '7.8', '7.9', '8.3', '7.5', '8.2', '7.5', '7.8', '8.4', '7.6', '7.6', '7.8', '7.9', '7.2', '8', '7.1', '8.1', '7.5', '8.1', '7.6', '8.2', '7.9', '6.7', '7.7', '7.7', '8.8', '8.1', '8.1', '7.2', '7.2', '8.3', '7.8', '8.3', '7.7', '8', '7.3', '7.8', '7.2', '7.9', '7.2', '7.7', '7.5', '7.5', '8.3', '7.9', '7.8', '8.3', '8.4', '8.2', '7.3', '8.1', '8']\n"
     ]
    }
   ],
   "source": [
    "ratings=[]\n",
    "for i in data.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    x=i.find('span',class_=\"ipl-rating-star__rating\").text\n",
    "    ratings.append(x)\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987704c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(2012)', '(1997)', '(1959)', '(2001)', '(1955)', '(1964)', '(2006)', '(2009)', '(2009)', '(1951)', '(1987)', '(1956)', '(1987)', '(1957)', '(1977)', '(1975)', '(1969)', '(1957)', '(1995)', '(1946)', '(1953)', '(1974)', '(1989)', '(1960)', '(1986)', '(1958)', '(1969)', '(2012)', '(1965)', '(1998)', '(1992)', '(1987)', '(1960)', '(2009)', '(1983)', '(1990)', '(1986)', '(1998)', '(2001)', '(2013)', '(1975)', '(1995)', '(2007)', '(1983)', '(1977)', '(2010)', '(1983)', '(2004)', '(1991)', '(1964)', '(1955)', '(2002)', '(1994)', '(2012)', '(1994)', '(2004)', '(2004)', '(1976)', '(1975)', '(2012)', '(1967)', '(1972)', '(2003)', '(1960)', '(1962)', '(1977)', '(1963)', '(2001)', '(2008)', '(2002)', '(1989)', '(1994)', '(2013)', '(1983)', '(2003)', '(1984)', '(1971)', '(2006)', '(2012)', '(2003)', '(1982)', '(2007)', '(1994)', '(I) (1964)', '(1978)', '(1969)', '(I) (1997)', '(2005)', '(1955)', '(2009)', '(1998)', '(2003)', '(2006)', '(1965)', '(1983)', '(1959)', '(2008)', '(2001)', '(2005)', '(1975)']\n"
     ]
    }
   ],
   "source": [
    "year=[]\n",
    "for i in data.find_all('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732e9f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAMES</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>YEAR OF RELESE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ship of Theseus</td>\n",
       "      <td>8</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iruvar</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaagaz Ke Phool</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lagaan: Once Upon a Time in India</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kanchivaram</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Monsoon Wedding</td>\n",
       "      <td>7.3</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Black</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Deewaar</td>\n",
       "      <td>8</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                NAMES Ratings YEAR OF RELESE\n",
       "0                     Ship of Theseus       8         (2012)\n",
       "1                              Iruvar     8.4         (1997)\n",
       "2                     Kaagaz Ke Phool     7.8         (1959)\n",
       "3   Lagaan: Once Upon a Time in India     8.1         (2001)\n",
       "4                     Pather Panchali     8.2         (1955)\n",
       "..                                ...     ...            ...\n",
       "95                        Apur Sansar     8.4         (1959)\n",
       "96                        Kanchivaram     8.2         (2008)\n",
       "97                    Monsoon Wedding     7.3         (2001)\n",
       "98                              Black     8.1         (2005)\n",
       "99                            Deewaar       8         (1975)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"NAMES\":names,\"Ratings\":ratings,\"YEAR OF RELESE\":year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e53e9",
   "metadata": {},
   "source": [
    "### 4) Write a python program to scrape details of all the posts from https://www.patreon.com/coreyms .Scrape the heading, date, content and the likes for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da0f73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.patreon.com/coreyms\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2d0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3fc249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headings=[]\n",
    "for i in data.find_all(\"div\",class_=\"sc-bBHxTw iloeMK\"):\n",
    "    c=i.find_all('span',class_=\"sc-1cvoi1y-0 hxhWXn\").text\n",
    "    headings.append(c)\n",
    "headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce7d4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date=[]\n",
    "for i in data.find_all('div',class_=\"sc-lgu5zg-0 dXpjXs\"):\n",
    "    x=i.find(\"p\",class_=\"sc-bqiRlB etUZPh sc-lgu5zg-1 bDqjCN\")\n",
    "    y=x.find('a',class_='sc-kfPuZi doifNG')\n",
    "    date.append(y.text)\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75429769",
   "metadata": {},
   "source": [
    "### 5) Write a python program to scrape house details from mentioned URL. It should include house title, location, area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4af294d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.nobroker.in/\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ab6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01636fb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (100623395.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in data.find_all('')\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "title=[]\n",
    "for i in data.find_all('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a7e34",
   "metadata": {},
   "source": [
    "### 6) Write a python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "https://www.bewakoof.com/bestseller?sort=popular ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37771786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.bewakoof.com/bestseller?sort=popular\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f300bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af762260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "for i in data.find_all('div',class_=\"productNaming bkf-ellipsis\"):\n",
    "    x=i.find('h2',class_='clr-shade4 h3-p-name   undefined false  ')\n",
    "    name.append(x)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31f76d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price=[]\n",
    "for i in data.find_all('div',class_='productPriceBox d-flex align-items-end  false'):\n",
    "    x=i.find('div',class_='discountedPriceText clr-p-black   false  ')\n",
    "    price.append(x.span.text)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d934f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60385bdf",
   "metadata": {},
   "source": [
    "### 7) Please visit https://www.cnbc.com/world/?region=world and scrap- a) headings b) date c) News link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c77f9a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e80181c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aff0617",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3245402747.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[23], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in data.find_all('')\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "headings=[]\n",
    "for i in data.find_all('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fa2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a8b48f6",
   "metadata": {},
   "source": [
    "### 8) Please visit https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-articles/ and scrap- a) Paper title b) date c) Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c2dc604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-articles/ \")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a73365f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8040828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_titles=[]\n",
    "for i in data.find_all('h2',class_='h5 article-title'):\n",
    "    paper_title.append(x.text)\n",
    "paper_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "595ddeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates=[]\n",
    "for i in data.find_all('p',class_='article-date'):\n",
    "    date.append(x.text)\n",
    "date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74bfb7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors=[]\n",
    "for i in data.find_all('p',class_=\"article-authors\"):\n",
    "    authors.append(i.text)\n",
    "authors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
